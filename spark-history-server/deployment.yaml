# Source: spark-history-server/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history-server
  labels:
    app.kubernetes.io/name: spark-history-server
    helm.sh/chart: spark-history-server-1.4.3
    app.kubernetes.io/instance: spark-history-server
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: spark-history-server
      app.kubernetes.io/instance: spark-history-server
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark-history-server
        app.kubernetes.io/instance: spark-history-server
    spec:
      serviceAccountName: spark-history-server
      containers:
      - name: spark-history-server
        image: "lightbend/spark-history-server:2.4.0"
        imagePullPolicy: IfNotPresent
        env:
        - name: HADOOP_CONF_DIR
          value: /etc/hadoop
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        ports:
        - name: historyport
          containerPort: 18080
          protocol: TCP
        resources:
          {}
        command:
        - "/bin/sh"
        - "-c"
        - >
          if [ "$enablePVC" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=file:/data/$eventsDir";
          elif [ "$enableGCS" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=$logDirectory";
            if [ "$enableIAM" == "false" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.google.cloud.auth.service.account.json.keyfile=/etc/secrets/$key";
            fi;
          elif [ "$enableS3" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.history.fs.logDirectory=$logDirectory \
              -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem";
            if [ -n "$endpoint" ] && [ "$endpoint" != "default" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.fs.s3a.endpoint=$endpoint";
            fi;
            if [ "$enableIAM" == "false" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.fs.s3a.access.key=$(cat /etc/secrets/${accessKeyName}) \
              -Dspark.hadoop.fs.s3a.secret.key=$(cat /etc/secrets/${secretKeyName})";
            fi;
          elif [ "$enableWASBS" == "true" ]; then
            container=$(cat /etc/secrets/${containerKeyName})
            storageAccount=$(cat /etc/secrets/${storageAccountNameKeyName})

            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.history.fs.logDirectory=$logDirectory \
              -Dspark.hadoop.fs.defaultFS=wasbs://$container@$storageAccount.blob.core.windows.net \
              -Dspark.hadoop.fs.wasbs.impl=org.apache.hadoop.fs.azure.NativeAzureFileSystem \
              -Dspark.hadoop.fs.AbstractFileSystem.wasbs.impl=org.apache.hadoop.fs.azure.Wasbs";
            if [ "$sasKeyMode" == "true" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                -Dspark.hadoop.fs.azure.local.sas.key.mode=true \
                -Dspark.hadoop.fs.azure.sas.$container.$storageAccount.blob.core.windows.net=$(cat /etc/secrets/${sasKeyName})";
            else
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
                -Dspark.hadoop.fs.azure.account.key.$storageAccount.blob.core.windows.net=$(cat /etc/secrets/${storageAccountKeyName})";
            fi;
          else
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=$logDirectory";
          fi;
          /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer;
        envFrom:
        - configMapRef:
            name: spark-history-server
        livenessProbe:
          httpGet:
            path: /
            port: historyport
        readinessProbe:
          httpGet:
            path: /
            port: historyport
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: nfs-pvc
---
