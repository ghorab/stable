# Source: openebs/templates/daemonset-ndm.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: openebs-ndm
  labels:
    app: openebs
    chart: openebs-1.11.1
    release: openebs
    heritage: Helm
    component: ndm
    openebs.io/component-name: ndm
    openebs.io/version: 1.11.0
spec:
  updateStrategy:
    type: "RollingUpdate"
  selector:
    matchLabels:
      app: openebs
      release: openebs
      component: ndm
  template:
    metadata:
      labels:
        app: openebs
        release: openebs
        component: ndm
        openebs.io/component-name: ndm
        name: openebs-ndm
        openebs.io/version: 1.11.0
    spec:
      serviceAccountName: openebs
      hostNetwork: true
      containers:
      - name: openebs-ndm
        image: "openebs/node-disk-manager-amd64:0.6.0"
        args:
          - -v=4
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: true
        env:
        # namespace in which NDM is installed will be passed to NDM Daemonset
        # as environment variable
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        # pass hostname as env variable using downward API to the NDM container
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        # specify the directory where the sparse files need to be created.
        # if not specified, then sparse files will not be created.
        - name: SPARSE_FILE_DIR
          value: "/var/openebs/sparse"
        # Size(bytes) of the sparse file to be created.
        - name: SPARSE_FILE_SIZE
          value: "10737418240"
        # Specify the number of sparse files to be created
        - name: SPARSE_FILE_COUNT
          value: "0"
        # Process name used for matching is limited to the 15 characters
        # present in the pgrep output.
        # So fullname can be used here with pgrep (cmd is < 15 chars).
        livenessProbe:
          exec:
            command:
            - pgrep
            - "ndm"
          initialDelaySeconds: 30
          periodSeconds: 60
        volumeMounts:
        - name: config
          mountPath: /host/node-disk-manager.config
          subPath: node-disk-manager.config
          readOnly: true
        - name: udev
          mountPath: /run/udev
        - name: procmount
          mountPath: /host/proc
          readOnly: true
        - name: basepath
          mountPath: /var/openebs/ndm
        - name: sparsepath
          mountPath: /var/openebs/sparse
      volumes:
      - name: config
        configMap:
          name: openebs-ndm-config
      - name: udev
        hostPath:
          path: /run/udev
          type: Directory
      # mount /proc (to access mount file of process 1 of host) inside container
      # to read mount-point of disks and partitions
      - name: procmount
        hostPath:
          path: /proc
          type: Directory
      - name: basepath
        hostPath:
          path: "/var/openebs/ndm"
          type: DirectoryOrCreate
      - name: sparsepath
        hostPath:
          path: /var/openebs/sparse
      # By default the node-disk-manager will be run on all kubernetes nodes
      # If you would like to limit this to only some nodes, say the nodes
      # that have storage attached, you could label those node and use
      # nodeSelector.
      #
      # e.g. label the storage nodes with - "openebs.io/nodegroup"="storage-node"
      # kubectl label node <node-name> "openebs.io/nodegroup"="storage-node"
      #nodeSelector:
      #  "openebs.io/nodegroup": "storage-node"
---
